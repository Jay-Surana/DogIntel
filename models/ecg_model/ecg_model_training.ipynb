{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"/content/drive/MyDrive/ECG/dataset.csv\")\n",
    "\n",
    "# Parse stringified lists/dicts into usable Python objects\n",
    "def parse_column(col):\n",
    "    return col.apply(lambda x: ast.literal_eval(x) if pd.notna(x) else [])\n",
    "\n",
    "df['segments_hr'] = parse_column(df['segments_hr'])\n",
    "df['segments_br'] = parse_column(df['segments_br'])\n",
    "df['bad_ecg'] = parse_column(df['bad_ecg'])\n",
    "\n",
    "# Feature engineering functions\n",
    "def extract_mean(segment_list):\n",
    "    if not segment_list:\n",
    "        return 0\n",
    "    return np.mean([seg['value'] for seg in segment_list if 'value' in seg])\n",
    "\n",
    "def extract_std(segment_list):\n",
    "    if not segment_list:\n",
    "        return 0\n",
    "    return np.std([seg['value'] for seg in segment_list if 'value' in seg])\n",
    "\n",
    "df['mean_hr'] = df['segments_hr'].apply(extract_mean)\n",
    "df['std_hr'] = df['segments_hr'].apply(extract_std)\n",
    "\n",
    "df['mean_br'] = df['segments_br'].apply(extract_mean)\n",
    "df['std_br'] = df['segments_br'].apply(extract_std)\n",
    "\n",
    "df['pulse_count'] = df['ecg_pulses'].apply(lambda x: len(ast.literal_eval(x)) if pd.notna(x) else 0)\n",
    "df['pulse_density'] = df['pulse_count'] / df['duration']\n",
    "\n",
    "df['bad_ecg_coverage'] = df['bad_ecg'].apply(lambda x: sum([interval[1] - interval[0] for interval in x]) if len(x) > 0 else 0)\n",
    "df['bad_ecg_ratio'] = df['bad_ecg_coverage'] / df['duration']\n",
    "\n",
    "# Label: Bad ECG if bad coverage > 100 seconds\n",
    "df['label'] = df['bad_ecg_coverage'].apply(lambda x: 1 if x > 100 else 0)\n",
    "\n",
    "# Drop rows with missing essential data\n",
    "df.dropna(subset=['duration', 'weight', 'age', 'mean_hr', 'mean_br'], inplace=True)\n",
    "\n",
    "# Features and target\n",
    "features = [\n",
    "    'duration', 'weight', 'age',\n",
    "    'mean_hr', 'std_hr',\n",
    "    'mean_br', 'std_br',\n",
    "    'pulse_count', 'pulse_density',\n",
    "    'bad_ecg_ratio'\n",
    "]\n",
    "X = df[features]\n",
    "y = df['label']\n",
    "\n",
    "# ðŸ” Split before scaling to avoid data leakage\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Normalize using only training data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train_scaled.shape[1],)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train\n",
    "model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=16,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test_scaled).flatten()\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "print(\"\\nâœ… Test Accuracy:\", round(accuracy_score(y_test, y_pred_classes) * 100, 2), \"%\")\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "# Save model\n",
    "model.save('/content/drive/MyDrive/ecg_model.keras')  # recommended\n",
    "model.save('/content/drive/MyDrive/ecg_model.h5')     # optional legacy\n",
    "\n",
    "\n",
    "print(\"âœ… Model saved in both .keras and .h5 formats.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model (change path if needed)\n",
    "model = keras.models.load_model('/content/drive/MyDrive/ecg_model.keras')\n",
    "\n",
    "# Create a fake ECG sample (random numbers matching input shape)\n",
    "# Replace (X_train.shape[1],) with your real input shape if needed\n",
    "# For example, if you trained on 10 features:\n",
    "sample_input = np.array([[0.1, -0.2, 0.3, 0.0, 0.1, 0.5, -0.4, 0.2, 0.3, 0.1]])\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(sample_input)\n",
    "\n",
    "# Show prediction\n",
    "predicted_class = (prediction > 0.5).astype(\"int32\")\n",
    "print(\"âœ… Predicted class:\", predicted_class[0][0])\n",
    "\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
